{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "485a2592-d59d-4bb9-bcf4-e9076c49a3e1",
   "metadata": {},
   "source": [
    "# \"Investor In Town\" -- Market/Property Evaluation Tool for Residential Real Estate Investors\n",
    "\n",
    "Often times, real eastate investors may have only a day or two in a city to look at potential investment properties and even less time to research them.  Our project is designed to provide residential real estate investors with a tool that uses calculated metrics to help narrow their search for investment properties based on a set of criteria. These metrics can be both market (city/state) and property based so that investors can start by narrowing from a list of cities, then filter individual properties within that market to determine which rental houses show attractive investment ratios and ultimately, plot their stops on a map.\n",
    "\n",
    "In this project, we will take a closer look at one of the most popular areas of the United States for residential real estate investors. The United States \"Sun Belt\" (which includes East Texas and the Southeastern US) has been offering attractive returns to investors over the last several years due to its high population and job growth.  But which cities in the Sun Belt offer the best investment properties, and which properties within those markets should an investor take a closer look at.  \"Investor In Town\" will answer these questions.\n",
    "\n",
    "The following 10 cities will be evaluated in this model:\n",
    "\n",
    "- Dallas, TX\n",
    "- Austin, TX\n",
    "- San Antonio, TX\n",
    "- Houston, TX\n",
    "- Atlanta, GA\n",
    "- Charlotte, NC\n",
    "- Jacksonville, FL\n",
    "- Tampa, FL\n",
    "- Orlando, FL\n",
    "- Miami, FL\n",
    "\n",
    "\n",
    "## Core Metrics\n",
    "\n",
    "### We will use a set of core metrics to evaluate and filter data on a market and property level. A list of these metrics can be found below, along with their calculation and goal outcome.\n",
    "\n",
    "**Market Level**\n",
    "\n",
    "1. Annual Population Growth by state % (2010 - 2023)\n",
    "\n",
    "2. Annual Job Growth by state % (2010 - 2023)\n",
    "\n",
    "3. City Price to Rent Ratio: Median Home Price / Annual Median Rent (monthly rent * 12) \n",
    "Goal <= 15\n",
    "\n",
    "4. Quality of Life Index\n",
    "\n",
    "5. Cost of Living Index (measure of overall affordability)\n",
    "\n",
    "6. Housing Price to Income Ratio (measure of housing affordability)\n",
    "\n",
    "\n",
    "**Property Level**\n",
    "\n",
    "1. Rent Ratio: Monthly Rent Estimate / Total Cost\n",
    "\n",
    "Goal >.55%\n",
    "\n",
    "2. Cap Rate:  Net Operating Income (NOI) / Total Cost\n",
    "\n",
    "Traditional Rental:  *Goal >= 5%*\n",
    "AirBNB Rental:  *Goal >= 9.5%*  \n",
    "\n",
    "## Equations and Variables\n",
    "\n",
    "# Formulas\n",
    "\n",
    "1.  Total Cost = List Price + Closing Fees\n",
    "2.  NOI = Gross Income - Annual Operating Expenses (OpEx)\n",
    "\n",
    "### Based on the above calculations, we will need to gather the following individual data points (variable and potential source listed below):\n",
    "\n",
    "1.  Address (Mashvisor API)\n",
    "2.  City (Mashvisor API)\n",
    "3.  State (Mashvisor API) \n",
    "4.  Zip Code (Mashvisor API)\n",
    "5.  Latitude (Mashvisor API)\n",
    "6.  Longitude (Mashvisor API)\n",
    "7.  List Price (Mashvisor API)\n",
    "8.  Square Feet (Mashvisor API)\n",
    "9.  Bed/Bath (Mashvisor API)\n",
    "10. Estimated Monthly Rent -- Traditional Rental (Mashvisor API)\n",
    "11. Estimated Monthly Rent -- AirBNB Rental\n",
    "12. Estimated Net Operating Income (NOI) -- Traditional Rental (Mashvisor API)\n",
    "13. Estimated Net Operating Income (NOI) -- AirBNB Rental (Mashvisor API)\n",
    "14. Median Home Price in a given city (Zillow csv: \"Zillow Home Value Index\")\n",
    "15. Annual Median Rent in a given city (Zillow csv:  \"Zillow Observed Rent Index\")\n",
    "16. Quality of Life Index (Numbeo)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb17aa65-0fa9-4afd-ae0f-18f437de6e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "import json\n",
    "import hvplot.pandas\n",
    "import ipywidgets as widgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7571e15a-a9d1-450d-80d9-8f0a15f17bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "api_key = os.getenv(\"X_RAPID_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33233a54-460e-41b8-ac05-73f75e26d41b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Population Growth By City Dictionary (Data from US Census)\n",
    "\n",
    "pop_growth_dict = {'city': ['Austin, TX', 'Orlando, FL', 'Houston, TX', 'San Antonio, TX', 'Dallas, TX', 'Charlotte, NC', 'Jacksonville, FL', 'Tampa, FL', 'Atlanta, GA', 'Miami, FL'],\n",
    "             'pop_growth_by_city': [25.84, 19.69, 17.36, 16.59, 16.58, 15.33, 13.71, 13.07, 12.15, 11.11]}\n",
    "\n",
    "pop_growth_df = pd.DataFrame.from_dict(pop_growth_dict)\n",
    "pop_growth_df.set_index(\"city\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26936c17-d3c9-4684-b411-2df497d59d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Population Growth by City\n",
    "\n",
    "pop_growth_df.hvplot.bar(\n",
    "    x='city', \n",
    "    y='pop_growth_by_city',\n",
    "    ylabel='Population Growth (%)', \n",
    "    xlabel='City',\n",
    "    rot=45,\n",
    "    ylim=(5, 45),\n",
    "    title='Population Growth by City -- Major \"Sun Belt\" Markets', \n",
    ").opts(\n",
    "    yformatter='%.0f',\n",
    "    color=\"blue\",\n",
    "    hover_color=\"orange\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b075c97-e33e-41a5-8be8-7eb0a4e87ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Job Growth By City Dictionary (Data from US Census)\n",
    "\n",
    "job_growth_dict = {'city': ['Dallas, TX', 'Charlotte, NC', 'Atlanta, GA', 'Miami, FL', 'Tampa, FL', 'Orlando, FL', 'Jacksonville, FL', 'Austin, TX', 'San Antonio, TX', 'Houston, TX'],\n",
    "             'job_growth_by_city': [6.5, 5.7, 5.4, 5.2, 5.1, 4.9, 4.8, 4.7, 4.6, 3.2]}\n",
    "\n",
    "job_growth_df = pd.DataFrame.from_dict(job_growth_dict)\n",
    "job_growth_df.set_index(\"city\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d17e90f2-56ef-4cd8-a20f-7c40b5c45096",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Job Growth by City\n",
    "\n",
    "job_growth_df.hvplot.bar(\n",
    "    x='city', \n",
    "    y='job_growth_by_city',\n",
    "    ylabel='Job Growth (%)', \n",
    "    xlabel='City',\n",
    "    rot=45,\n",
    "    ylim=(2, 8),\n",
    "    title='Job Growth by City -- Major \"Sun Belt\" Markets', \n",
    ").opts(\n",
    "    yformatter='%.0f',\n",
    "    color=\"blue\",\n",
    "    hover_color=\"orange\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83b2ec9d-1ef6-4662-aa51-1769cd9cdbe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Begin City-Level Data \n",
    "# Create Quality of Life Index (QOLI) Dictionary (Data from Numbeo)\n",
    "\n",
    "qoli_dict = {'city': ['Jacksonville, FL', 'Orlando, FL', 'Tampa, FL', 'San Antonio, TX', 'Austin, TX', 'Dallas, TX', 'Charlotte, NC', 'Houston, TX', 'Atlanta, GA', 'Miami, FL'],\n",
    "             'quality_of_life_index': [176.7, 176.6, 176.6, 176.5, 176.4, 176.2, 174.4, 168.5, 166.8, 153.6]}\n",
    "\n",
    "qoli_df = pd.DataFrame.from_dict(qoli_dict)\n",
    "qoli_df.set_index(\"city\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21bb4faf-c7fb-48ab-8428-66f1f476ca75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Quality of Life Index by City\n",
    "\n",
    "qoli_df.hvplot.bar(\n",
    "    x='city', \n",
    "    y='quality_of_life_index',\n",
    "    ylabel='Quality of Life Index', \n",
    "    xlabel='City',\n",
    "    rot=45,\n",
    "    ylim=(125, 185),\n",
    "    title='Quality of Life Index -- Major \"Sun Belt\" Markets', \n",
    ").opts(\n",
    "    yformatter='%.0f',\n",
    "    color=\"blue\",\n",
    "    hover_color=\"orange\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcb46eaf-6078-4822-a163-0dc64a4ef8f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Cost of Living Index (COLI) Dictionary (Data from Numbeo)\n",
    "\n",
    "coli_dict = {'city': ['San Antonio, TX', 'Jacksonville, FL', 'Houston, TX', 'Orlando, FL', 'Austin, TX', 'Atlanta, GA', 'Tampa, FL', 'Dallas, TX', 'Miami, FL', 'Charlotte, NC'],\n",
    "             'cost_of_living_index': [67.4, 67.9, 70.0, 72.1, 74.0, 74.0, 75.2, 77.4, 81.5, 81.6]}\n",
    "\n",
    "coli_df = pd.DataFrame.from_dict(coli_dict)\n",
    "coli_df.set_index(\"city\")\n",
    "coli_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84817ec6-1bf8-4b4d-97fd-aec232a25583",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Cost of Living Index by City\n",
    "\n",
    "coli_df.hvplot.bar(\n",
    "    x='city', \n",
    "    y='cost_of_living_index',\n",
    "    ylabel='Cost of Living Index', \n",
    "    xlabel='City',\n",
    "    rot=45,\n",
    "    ylim=(50, 100),\n",
    "    title='Cost of Living Index -- Major \"Sun Belt\" Markets', \n",
    ").opts(\n",
    "    yformatter='%.0f',\n",
    "    color=\"blue\",\n",
    "    hover_color=\"orange\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db0c0a10-112b-44ea-bf66-743657919204",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Housing Price to Income Ratio (p2i) Dictionary (Data from Numbeo)\n",
    "\n",
    "p2i_dict = {'city': ['Houston, TX', 'Dallas, TX', 'Atlanta, GA', 'Charlotte, NC', 'San Antonio, TX', 'Jacksonville, FL', 'Orlando, FL', 'Tampa, FL', 'Miami, FL', 'Austin, TX'],\n",
    "             'price_to_income_ratio': [2.2, 2.8, 3.1, 3.7, 4.2, 4.3, 4.5, 4.5, 5.3, 6.1]}\n",
    "\n",
    "p2i_df = pd.DataFrame.from_dict(p2i_dict)\n",
    "p2i_df.set_index(\"city\")\n",
    "p2i_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d17cb365-210e-4022-a7bc-d5e13c86159a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Housing Price to Income Ratio by City (Data from Numbeo)\n",
    "\n",
    "p2i_df.hvplot.bar(\n",
    "    x='city', \n",
    "    y='price_to_income_ratio',\n",
    "    ylabel='Price to Income Ratio', \n",
    "    xlabel='City',\n",
    "    rot=45,\n",
    "    ylim=(0, 8),\n",
    "    title='Housing Price to Income Ratio -- Major \"Sun Belt\" Markets', \n",
    ").opts(\n",
    "    yformatter='%.0f',\n",
    "    color=\"blue\",\n",
    "    hover_color=\"orange\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19a568f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "state = widgets.Dropdown(\n",
    "    options=[('Florida', 'FL'), ('Texas', 'TX'), ('North Carolina', 'NC'), ('Georgia', 'GA')],\n",
    "    value='FL',\n",
    "    description='State:',\n",
    ")\n",
    "\n",
    "state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1e5465e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "texas = ['Houston', 'Dallas', 'San Antonio', 'Austin']\n",
    "florida = ['Orlando', 'Tampa', 'Miami', 'Jacksonville']\n",
    "georgia = ['Atlanta']\n",
    "north_carolina = ['Charlotte']\n",
    "\n",
    "\n",
    "\n",
    "def state_selection(selected):\n",
    "    options = []\n",
    "    if selected == 'FL':\n",
    "        for option in florida:\n",
    "            options.append(option)\n",
    "        return options\n",
    "    elif selected == 'TX':\n",
    "        for option in texas:\n",
    "            options.append(option)\n",
    "        return options\n",
    "    elif selected == 'GA':\n",
    "        options = georgia\n",
    "        return options\n",
    "    else:\n",
    "        options = north_carolina\n",
    "        display(options)\n",
    "        return options \n",
    "\n",
    "selected_state = state_selection(state.value)\n",
    "\n",
    "city = widgets.Dropdown(\n",
    "    options=selected_state,\n",
    "    value=None,\n",
    "    description='City:',\n",
    ")\n",
    "\n",
    "city"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e59a9be-6043-4910-b380-2e99ee8f1a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call mashvisor api for property dataframe\n",
    "url = f\"https://api.mashvisor.com/v1.1/client/city/properties/{state.value}/{city.value}\"\n",
    "display(url)\n",
    "payload={}\n",
    "headers = {\n",
    "  'x-api-key': '6c4620ed-a730-48fb-9b1d-8d93ea627343'\n",
    "}\n",
    "response = requests.request(\"GET\", url, headers=headers, data=payload)\n",
    "\n",
    "#reformat json data to dictionary\n",
    "data = response.json()\n",
    "mashvisor_data = json.dumps(data, indent=4)\n",
    "new_dict = json.loads(mashvisor_data)\n",
    "new_dict\n",
    "mashvisor_dict = new_dict['content']['properties']\n",
    "#mashvisor_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af2b6cff-05b7-45dd-ae54-3bd6c9213951",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new property dictionary and convert to a pandas dataframe\n",
    "new_list = []\n",
    "for prop in mashvisor_dict:\n",
    "    new_dict = {\n",
    "        \"property_id\": prop[\"id\"],\n",
    "        \"address\": prop[\"address\"],\n",
    "        \"city\": prop[\"city\"],\n",
    "        \"state\": prop[\"state\"],\n",
    "        \"zip_code\": prop[\"zip_code\"],\n",
    "        \"latitude\": prop[\"latitude\"],\n",
    "        \"longitude\": prop[\"longitude\"],\n",
    "        \"list_price\": prop[\"list_price\"],\n",
    "        \"square_ft\": prop[\"sqft\"],\n",
    "        \"beds\": prop[\"beds\"],\n",
    "        \"baths\": prop[\"baths\"],\n",
    "        \"price_per_sqft\": prop[\"price_per_sqft\"],\n",
    "        \"trad_monthly_rent\": prop[\"traditional_rental\"],\n",
    "        \"airbnb_monthly_rent\": prop[\"airbnb_rental\"],\n",
    "        #\"reg_ROI\": prop[\"traditional_ROI\"],\n",
    "        #\"airbnb_ROI\": prop[\"airbnb_ROI\"],\n",
    "        \"trad_cap_rate\": prop[\"traditional_cap\"],\n",
    "        \"airbnb_cap_rate\": prop[\"airbnb_cap\"],\n",
    "        #\"reg_COC\": [\"COC\"][1],\n",
    "        #\"airbnb_COC\": [\"COC\"][0]\n",
    "    }        \n",
    "    new_list.append(new_dict)\n",
    "new_list\n",
    "property_df = pd.DataFrame(new_list)\n",
    "property_df.dropna()\n",
    "property_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "effb2f08-d2d2-42f9-86b0-d2acbfba2454",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add columns, clean and sort data, and create a property dataframe to find the top 20 properties on the market\n",
    "property_df[\"rent_ratio\"] = property_df[\"trad_monthly_rent\"] / property_df[\"list_price\"]\n",
    "property_df[\"rent_ratio\"] = property_df[\"rent_ratio\"] * 100\n",
    "property_df.set_index(\"property_id\")\n",
    "property_df.sort_values(\"trad_cap_rate\", ascending=False)\n",
    "property_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c0c101d-3e80-439a-8b32-05e18af4c0a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Market Summary Dataframe\n",
    "market_summary_df = pd.DataFrame({'avg_list_price': property_df[\"list_price\"].mean(),\n",
    "                          'avg_sqft': property_df[\"square_ft\"].mean(),\n",
    "                          'avg_monthly_rent_trad': property_df[\"trad_monthly_rent\"].mean(),\n",
    "                          'avg_monthly_rent_airbnb': property_df[\"airbnb_monthly_rent\"].mean(),\n",
    "                          'avg_cap_rate_trad': property_df[\"trad_cap_rate\"].mean(),\n",
    "                          'avg_cap_rate_airbnb': property_df[\"airbnb_cap_rate\"].mean(),\n",
    "                          'avg_rent_ratio': avg_monthly_rent_trad / avg_list_price\n",
    "                         }, index=[0])\n",
    "\n",
    "market_summary_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44ae27bf-e3c4-475f-a06c-27ed8ba51194",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Futher filter data to return only those homes that meet the goal criteria listed in the project description \n",
    "goal_df = property_df.loc[(property_df['trad_cap_rate'] >= 5) & (property_df['rent_ratio'] > .55) & (property_df['airbnb_cap_rate'] > 9.5)]\n",
    "goal_df.sort_values(\"trad_cap_rate\", ascending=False)\n",
    "goal_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a81ecc34-cc21-4f52-a157-a47b9ba016d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map the properties that meet the goal criteria\n",
    "\n",
    "goal_property_plot = goal_df.hvplot.points(\n",
    "    'longitude', \n",
    "    'latitude', \n",
    "    geo=True, \n",
    "    color='address',\n",
    "    alpha=0.8,\n",
    "    size = 500,\n",
    "    tiles='OSM',\n",
    "    frame_width = 700,\n",
    "    frame_height = 500\n",
    "    )\n",
    "\n",
    "# Show the Plot\n",
    "goal_property_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36f01226-6d37-4f2e-a44e-fe3b7a3b7a69",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "379a480e-edcc-4820-822f-33e3f572dadc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lowest common denomenator for the data: 2015-2019\n",
    "#15, 16, 17,18,19\n",
    "#1. drop columns in 4 data frames... so only those years \n",
    "#need to drop so it only has one of each year. because population and real inflation only have one year.\n",
    "#I will pick the last data sample of the Year.\n",
    "# all df should be about same size...\n",
    "\n",
    "#data cleaning.\n",
    "\n",
    "\n",
    "#Lowest common denominator for location: States\n",
    "#2.need to take all state information on property value and rent value then give an everage for the state\n",
    "\n",
    "3.#calculate percent change per year and add \n",
    "#column or row?\n",
    "\n",
    "# - Population growth\n",
    "# - Real Income Growth\n",
    "# - home Value growth\n",
    "# - rent growth\n",
    "\n",
    "\n",
    "#4concatenate dataframe\n",
    "#5compare 2015-2019 state data in 4 heatmaps.\n",
    "# - Population growth\n",
    "# - Real Income Growth\n",
    "# - home Value growth\n",
    "# - rent growth\n",
    "\n",
    "\n",
    "\n",
    "#meeting with mike on 2/20/2023\n",
    "# have to find better data that matches project...\n",
    "#created two awesome usa charts that show pop and job grwoth 2010 to 2023.\n",
    "\n",
    "#steps on 2/22/2023\n",
    "#drop some extra columns on seaborn correlation and just show correlation between home value and population.\n",
    "# clean code and merge.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b99a0a5-b4ac-405e-b059-f8377a463856",
   "metadata": {},
   "outputs": [],
   "source": [
    "###import pandas library and pathlib library to read in csv.\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from pathlib import Path\n",
    "\n",
    "###reading in Csv to filepath then using read_csv function to dataframe.\n",
    "# this files has all the home values average per\n",
    "file_path = Path(\"Resources/County_zillow_home_value_index.csv\")\n",
    "df_value = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfd59d34-12a0-465f-a451-a326b22730a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "###this code turns the datafram columns into a list so I can see which Columns I wanted to drop.\n",
    "my_list = list(df_value)\n",
    "print (my_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8900fb6a-424a-42f3-9c16-98d8d86caee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#drops all the columns that arent the last data entry of the month.\n",
    "df_value.drop(columns=[ '1/31/2000', '2/29/2000', '3/31/2000', '4/30/2000', '5/31/2000', '6/30/2000', '7/31/2000', '8/31/2000', '9/30/2000', '10/31/2000', '11/30/2000', '12/31/2000', '1/31/2001', '2/28/2001', '3/31/2001', '4/30/2001', '5/31/2001', '6/30/2001', '7/31/2001', '8/31/2001', '9/30/2001', '10/31/2001', '11/30/2001', '12/31/2001', '1/31/2002', '2/28/2002', '3/31/2002', '4/30/2002', '5/31/2002', '6/30/2002', '7/31/2002', '8/31/2002', '9/30/2002', '10/31/2002', '11/30/2002', '12/31/2002', '1/31/2003', '2/28/2003', '3/31/2003', '4/30/2003', '5/31/2003', '6/30/2003', '7/31/2003', '8/31/2003', '9/30/2003', '10/31/2003', '11/30/2003', '12/31/2003', '1/31/2004', '2/29/2004', '3/31/2004', '4/30/2004', '5/31/2004', '6/30/2004', '7/31/2004', '8/31/2004', '9/30/2004', '10/31/2004', '11/30/2004', '12/31/2004', '1/31/2005', '2/28/2005', '3/31/2005', '4/30/2005', '5/31/2005', '6/30/2005', '7/31/2005', '8/31/2005', '9/30/2005', '10/31/2005', '11/30/2005', '12/31/2005', '1/31/2006', '2/28/2006', '3/31/2006', '4/30/2006', '5/31/2006', '6/30/2006', '7/31/2006', '8/31/2006', '9/30/2006', '10/31/2006', '11/30/2006', '12/31/2006', '1/31/2007', '2/28/2007', '3/31/2007', '4/30/2007', '5/31/2007', '6/30/2007', '7/31/2007', '8/31/2007', '9/30/2007', '10/31/2007', '11/30/2007', '12/31/2007', '1/31/2008', '2/29/2008', '3/31/2008', '4/30/2008', '5/31/2008', '6/30/2008', '7/31/2008', '8/31/2008', '9/30/2008', '10/31/2008', '11/30/2008', '12/31/2008', '1/31/2009', '2/28/2009', '3/31/2009', '4/30/2009', '5/31/2009', '6/30/2009', '7/31/2009', '8/31/2009', '9/30/2009', '10/31/2009', '11/30/2009', '12/31/2009', '1/31/2010', '2/28/2010', '3/31/2010', '4/30/2010', '5/31/2010', '6/30/2010', '7/31/2010', '8/31/2010', '9/30/2010', '10/31/2010', '11/30/2010', '12/31/2010', '1/31/2011', '2/28/2011', '3/31/2011', '4/30/2011', '5/31/2011', '6/30/2011', '7/31/2011', '8/31/2011', '9/30/2011', '10/31/2011', '11/30/2011', '12/31/2011', '1/31/2012', '2/29/2012', '3/31/2012', '4/30/2012', '5/31/2012', '6/30/2012', '7/31/2012', '8/31/2012', '9/30/2012', '10/31/2012', '11/30/2012', '12/31/2012', '1/31/2013', '2/28/2013', '3/31/2013', '4/30/2013', '5/31/2013', '6/30/2013', '7/31/2013', '8/31/2013', '9/30/2013', '10/31/2013', '11/30/2013', '12/31/2013', '1/31/2014', '2/28/2014', '3/31/2014', '4/30/2014', '5/31/2014', '6/30/2014', '7/31/2014', '8/31/2014', '9/30/2014', '10/31/2014', '11/30/2014', '12/31/2014', '1/31/2015', '2/28/2015', '3/31/2015', '4/30/2015', '5/31/2015', '6/30/2015', '7/31/2015', '8/31/2015', '9/30/2015', '10/31/2015', '11/30/2015', '1/31/2016', '2/29/2016', '3/31/2016', '4/30/2016', '5/31/2016', '6/30/2016', '7/31/2016', '8/31/2016', '9/30/2016', '10/31/2016', '11/30/2016', '1/31/2017', '2/28/2017', '3/31/2017', '4/30/2017', '5/31/2017', '6/30/2017', '7/31/2017', '8/31/2017', '9/30/2017', '10/31/2017', '11/30/2017', '1/31/2018', '2/28/2018', '3/31/2018', '4/30/2018', '5/31/2018', '6/30/2018', '7/31/2018', '8/31/2018', '9/30/2018', '10/31/2018', '11/30/2018', '1/31/2019', '2/28/2019', '3/31/2019', '4/30/2019', '5/31/2019', '6/30/2019', '7/31/2019', '8/31/2019', '9/30/2019', '10/31/2019', '11/30/2019', '1/31/2020', '2/29/2020', '3/31/2020', '4/30/2020', '5/31/2020', '6/30/2020', '7/31/2020', '8/31/2020', '9/30/2020', '10/31/2020', '11/30/2020', '12/31/2020', '1/31/2021', '2/28/2021', '3/31/2021', '4/30/2021', '5/31/2021', '6/30/2021', '7/31/2021', '8/31/2021', '9/30/2021', '10/31/2021', '11/30/2021', '12/31/2021', '1/31/2022', '2/28/2022', '3/31/2022', '4/30/2022', '5/31/2022', '6/30/2022', '7/31/2022', '8/31/2022', '9/30/2022', '10/31/2022', '11/30/2022', '12/31/2022','1/31/2023'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4ddf49e-4432-4c52-9e68-fa1b93aa2bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#renames all columns into their own data frames.\n",
    "df_value_2015 = df_value.rename(columns={\"State\": \"Value\"}).groupby('Value', as_index=True)['12/31/2015'].mean()\n",
    "df_value_2016 = df_value.rename(columns={\"State\": \"Value\"}).groupby('Value', as_index=True)['12/31/2016'].mean()\n",
    "df_value_2017 = df_value.rename(columns={\"State\": \"Value\"}).groupby('Value', as_index=True)['12/31/2017'].mean()\n",
    "df_value_2018 = df_value.rename(columns={\"State\": \"Value\"}).groupby('Value', as_index=True)['12/31/2018'].mean()\n",
    "df_value_2019 = df_value.rename(columns={\"State\": \"Value\"}).groupby('Value', as_index=True)['12/31/2019'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bdea0a8-c89b-4d25-8a89-415b5555764e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Concats all the new dataframes\n",
    "df_value_state = pd.concat([df_value_2015, df_value_2016, df_value_2017, df_value_2018, df_value_2019], axis=1)\n",
    "\n",
    "#Renames Values\n",
    "df_value1 = df_value_state.rename(columns={\"12/31/2015\": \"2015_Val\", \"12/31/2016\": \"2016_Val\", \"12/31/2017\": \"2017_Val\", \"12/31/2018\": \"2018_Val\",\"12/31/2019\": \"2019_Val\"})\n",
    "\n",
    "#Calculates Percent Change then creates new percent change dataframe\n",
    "df_value1_per = df_value1.pct_change(axis=\"columns\")\n",
    "df_value1_per"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29580205-1370-4364-952e-8f8c118fc140",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reads in all the rent data from zillow into a CSV, ver similar files to value CSV\n",
    "file_path2 = Path(\"Resources/County_zillow_observed_rent_index.csv\")\n",
    "df_rent = pd.read_csv(file_path2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6be62da-0e3d-4a13-93ca-24d651958864",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reads in list and drops columns to match other csv\n",
    "my_list2 = list(df_rent)\n",
    "print (my_list2)\n",
    "df_rent.drop(columns = [ '3/31/2015', '4/30/2015', '5/31/2015', '6/30/2015', '7/31/2015', '8/31/2015', '9/30/2015', '10/31/2015', '11/30/2015', '1/31/2016', '2/29/2016', '3/31/2016', '4/30/2016', '5/31/2016', '6/30/2016', '7/31/2016', '8/31/2016', '9/30/2016', '10/31/2016', '11/30/2016','1/31/2017', '2/28/2017', '3/31/2017', '4/30/2017', '5/31/2017', '6/30/2017', '7/31/2017', '8/31/2017', '9/30/2017', '10/31/2017', '11/30/2017','1/31/2018', '2/28/2018', '3/31/2018', '4/30/2018', '5/31/2018', '6/30/2018', '7/31/2018', '8/31/2018', '9/30/2018', '10/31/2018', '11/30/2018','1/31/2019', '2/28/2019', '3/31/2019', '4/30/2019', '5/31/2019', '6/30/2019', '7/31/2019', '8/31/2019', '9/30/2019', '10/31/2019', '11/30/2019','1/31/2020', '2/29/2020', '3/31/2020', '4/30/2020', '5/31/2020', '6/30/2020', '7/31/2020', '8/31/2020', '9/30/2020', '10/31/2020', '11/30/2020', '12/31/2020', '1/31/2021', '2/28/2021', '3/31/2021', '4/30/2021', '5/31/2021', '6/30/2021', '7/31/2021', '8/31/2021', '9/30/2021', '10/31/2021', '11/30/2021', '12/31/2021', '1/31/2022', '2/28/2022', '3/31/2022', '4/30/2022', '5/31/2022', '6/30/2022', '7/31/2022', '8/31/2022', '9/30/2022', '10/31/2022', '11/30/2022', '12/31/2022',  '1/31/2023'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8626c8a-0fa3-460d-a48c-6cf4c4fb68f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I created new dataframes that are all the rent data averaged by state\n",
    "df_rent_2015 = df_rent.rename(columns={\"State\": \"Rent\"}).groupby('Rent', as_index=True)['12/31/2015'].mean()\n",
    "df_rent_2016 = df_rent.rename(columns={\"State\": \"Rent\"}).groupby('Rent', as_index=True)['12/31/2016'].mean()\n",
    "df_rent_2017 = df_rent.rename(columns={\"State\": \"Rent\"}).groupby('Rent', as_index=True)['12/31/2017'].mean()\n",
    "df_rent_2018 = df_rent.rename(columns={\"State\": \"Rent\"}).groupby('Rent', as_index=True)['12/31/2018'].mean()\n",
    "df_rent_2019 = df_rent.rename(columns={\"State\": \"Rent\"}).groupby('Rent', as_index=True)['12/31/2019'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e29abf23-4413-45d6-a97e-f5bc81b5f347",
   "metadata": {},
   "outputs": [],
   "source": [
    "# concattenated the rent data.\n",
    "df_rent_state = pd.concat([df_rent_2015, df_rent_2016, df_rent_2017, df_rent_2018, df_rent_2019], axis=1)\n",
    "df_rent_state\n",
    "\n",
    "#renamed the columns\n",
    "df_rent1 = df_rent_state.rename(columns={\"12/31/2015\": \"2015_rent\", \"12/31/2016\": \"2016_rent\", \"12/31/2017\": \"2017_rent\", \"12/31/2018\": \"2018_rent\",\"12/31/2019\": \"2019_rent\"})\n",
    "\n",
    "#creates new Dataframe that is percent change.\n",
    "df_rent1_per = df_rent1.pct_change(axis=\"columns\")\n",
    "df_rent1_per"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a50999fc-d618-4c33-8ce3-63e524206a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reads in CSV, this data was by year so less data cleaning.\n",
    "file_path3 = Path(\"Resources/Population_data.csv\")\n",
    "df_population = pd.read_csv(file_path3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d02692-24b7-462f-967d-059f1abdb4fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#need to drop years not 2015 - 2019\n",
    "df_population1 = df_population.drop(columns=[\"2010\",\"2011\",\"2012\",\"2013\",\"2014\",\"Census\",\"Estimates Base\"]).rename(columns={\"Geographic Area resident estimates\": \"Population\", \"2015\": \"2015_pop\", \"2016\": \"2016_pop\", \"2017\": \"2017_pop\", \"2018\": \"2018_pop\",\"2019\": \"2019_pop\"}).set_index('Population')\n",
    "\n",
    "\n",
    "#I am going to change the state data to all be the abbreviations... in the excel..\n",
    "\n",
    "\n",
    "#helpful code that deleted all commas then turned data to a numneric.\n",
    "df_population1 = df_population1.replace(',','', regex=True)\n",
    "c = df_population1.select_dtypes(object).columns\n",
    "df_population1[c] = df_population1[c].apply(pd.to_numeric,errors='coerce')\n",
    "df_population1_per = df_population1.pct_change(axis=\"columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcca157d-3f3e-4b3d-ae7c-9ca69335a6bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reads in CSV, this data was by year so less data cleaning.\n",
    "file_path4 = Path(\"Resources/Real_income.csv\")\n",
    "df_income = pd.read_csv(file_path4)\n",
    "df_income1 = df_income.drop(columns=[\"2008\",\"2009\",\"2010\",\"2011\",\"2012\",\"2013\",\"2014\",\"Unnamed: 0\",\"Unnamed: 2\",\"Unnamed: 3\",\"Unnamed: 4\",\"Unnamed: 5\",\"Unnamed: 6\",\"Unnamed: 7\",\"2020\",\"2021\"]).rename(columns={\"Unnamed: 1\": \"Income\",\"2015\": \"2015_inc\", \"2016\": \"2016_inc\", \"2017\": \"2017_inc\", \"2018\": \"2018_inc\",\"2019\": \"2019_inc\"}).set_index('Income')\n",
    "#I am going to change the state data to all be the abbreviations... in the excel..\n",
    "\n",
    "df_income1_per = df_income1.pct_change(axis=\"columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82068fd4-0a43-4b4a-9b6f-2c838460d27e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Concatenated all the information into a \"super Dataframe\"\n",
    "df_super = pd.concat([df_income1, df_population1, df_rent1, df_value1], axis=1)\n",
    "df_super\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6f59f6e-799d-4188-a334-1d6b52193d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "from pandas import DataFrame\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "df_super_per_corr = df_super_per.drop(columns=['2015_inc','2016_inc','2017_inc','2018_inc','2015_pop', '2016_pop', '2017_pop', '2018_pop', '2015_rent', '2016_rent', '2017_rent', '2018_rent']).corr()\n",
    "\n",
    "value19_df_super_per_corr = df_super_per_corr\n",
    "\n",
    "\n",
    "sns.heatmap(value19_df_super_per_corr, annot=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d749fab2-3a34-4693-b12d-3a76a07b5316",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#reads in new jobs data and cleans it to 2010 and 2023 and percent change\n",
    "\n",
    "file_path_job = Path(\"Resources/job_data_2023.csv\")\n",
    "df_job = pd.read_csv(file_path_job)\n",
    "df_job = df_job.drop(columns=['U.S. Rank','% Change','Job Growth (In Thousands)'])\n",
    "df_job = df_job.set_index('State')\n",
    "df_job\n",
    "df_job['Percent Change'] = (df_job['# of Jobs 2022'] - df_job['# of Jobs 2010']) / df_job['# of Jobs 2010'] * 100\n",
    "df_job1 = df_job.drop(df_job.index[52:253])\n",
    "df_job1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7856c0b1-e956-4635-8639-6aa283fa4a3d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#reads in new population  data and cleans it to 2010 and 2023 and percent change\n",
    "file_path_pop = Path(\"Resources/pop_data_2023.csv\")\n",
    "df_pop = pd.read_csv(file_path_pop)\n",
    "df_pop = df_pop.set_index('state')\n",
    "df_pop['growthSince2010'] = df_pop['growthSince2010'] * 100 \n",
    "df_pop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e50b660b-9905-40cb-88da-83c7a6096d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import geopandas library\n",
    "import geopandas as gpd\n",
    "\n",
    "# Load file has coordinated for where the state information goes on the graphic... very intresting Geo pandas\n",
    "url = \"https://raw.githubusercontent.com/holtzy/The-Python-Graph-Gallery/master/static/data/us_states_hexgrid.geojson.json\"\n",
    "geoData = gpd.read_file(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88383d0f-4e6f-4b36-9a19-fd66b7b25bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the geoplot library.\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set the plot size for this notebook:\n",
    "plt.rcParams[\"figure.figsize\"]=13,13\n",
    "\n",
    "# Draw a map with matplotlib\n",
    "geoData.plot(color=\"white\", edgecolor='black', linewidth=.5);\n",
    "plt.axis('off');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2af1f72-26f8-4ac5-942e-f418a43e61d8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# add a \"centroid\" column with the centroid position of each county\n",
    "geoData['centroid'] = geoData['geometry'].apply(lambda x: x.centroid)\n",
    "\n",
    "# redraw the empty hexbin map:\n",
    "geoData.plot(color=\"white\", edgecolor='black', linewidth=.5);\n",
    "plt.axis('off');\n",
    "\n",
    "# for each county, annotate with the county name located at the centroid coordinates \n",
    "for idx, row in geoData.iterrows():\n",
    "    plt.annotate(text=row['iso3166_2'], xy=row['centroid'].coords[0],fontsize=12, horizontalalignment='center', va='center')\n",
    "    # Initialize the figure\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ddd813d-f020-4659-87be-cb8571c6e52c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "geoData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "586083a2-cd2c-4447-adb0-18dca9ab7a83",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "geoData['state'] = geoData['google_name'].str.replace(' \\(United States\\)','')\n",
    "geoData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e97b78db-dc14-417a-bd71-cbdffb566c17",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#JOIN MY DATA\n",
    "geoData = geoData.set_index('iso3166_2',drop=False)\n",
    "geoData = geoData.join(df_super, rsuffix='_house_Value').join(df_job1, rsuffix='_job').join(df_pop)\n",
    "geoData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8377fa8d-9d23-4cf1-9ecd-c7c1258eea41",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#test if working with my data from super correlation dataframe\n",
    "geoData.plot(column=\"2015_inc\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19fae242-d601-4cad-a556-45941b5c97c5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#used to create the normalize min and max for color scale.\n",
    "print(geoData['2015_inc'].min())\n",
    "print(geoData['2015_inc'].max())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5da046a-3e92-441a-8051-b7e6afcef325",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#size of plot\n",
    "fig, ax = plt.subplots(1, figsize=(13, 13))\n",
    "\n",
    "\n",
    "#plots data, annotates it and puts the state names + puts a colorbar to show scale\n",
    "\n",
    "geoData.plot(\n",
    "    ax=ax,\n",
    "    column=\"2015_inc\", \n",
    "    cmap=\"BuPu\", \n",
    "    norm=plt.Normalize(vmin=38708.0, vmax=61470.0),\n",
    "    edgecolor='white', \n",
    "    linewidth=.5\n",
    ");\n",
    "\n",
    "ax.axis('off');\n",
    "\n",
    "ax.annotate('Average Real Income 2019', xy=(350,550),  xycoords='axes pixels', horizontalalignment='left', verticalalignment='top', fontsize=14, color='black')\n",
    "ax.annotate('Yessir', xy=(350,525),  xycoords='axes pixels', horizontalalignment='left', verticalalignment='top', fontsize=11, color='#808080')\n",
    "ax.annotate('python-graph-gallery.com', xy=(900,0),  xycoords='axes pixels', horizontalalignment='left', verticalalignment='top', fontsize=8, color='#808080')\n",
    "\n",
    "for idx, row in geoData.iterrows():\n",
    "    ax.annotate(\n",
    "        text=row['iso3166_2'], \n",
    "        xy=row['centroid'].coords[0], \n",
    "        horizontalalignment='center', \n",
    "        va='center',\n",
    "        color=\"black\",\n",
    "        zorder=3\n",
    "    )\n",
    "    \n",
    "    sm = plt.cm.ScalarMappable(cmap='BuPu', norm=plt.Normalize(vmin=38708.0, vmax=61470.0))\n",
    "fig.colorbar(sm, orientation=\"horizontal\", aspect=50, fraction=0.005, pad=0 );\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a43b178-0cba-42a7-beba-5d556471030e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#used to create the normalize min and max for color scale.\n",
    "print(geoData['growthSince2010'].min())\n",
    "print(geoData['growthSince2010'].max())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39bcb7a8-e1e3-450d-ba7b-fe6886809754",
   "metadata": {},
   "outputs": [],
   "source": [
    "#takes zillow data and cleans it into just data by city 2023\n",
    "file_pathr = Path(\"Resources/City_zori_sm_month.csv\")\n",
    "df_rent2 = pd.read_csv(file_pathr)\n",
    "\n",
    "file_pathv = Path(\"Resources/City_zhvi_uc_sfrcondo_tier_0.33_0.67_sm_sa_month.csv\")\n",
    "df_value_city = pd.read_csv(file_pathv)\n",
    "\n",
    "\n",
    "df_value_city = df_value_city.set_index(['RegionName','State'])\n",
    "df_value_city = df_value_city.drop(columns = [ '2000-01-31', '2000-02-29', '2000-03-31', '2000-04-30', '2000-05-31', '2000-06-30', '2000-07-31', '2000-08-31', '2000-09-30', '2000-10-31', '2000-11-30', '2000-12-31', '2001-01-31', '2001-02-28', '2001-03-31', '2001-04-30', '2001-05-31', '2001-06-30', '2001-07-31', '2001-08-31', '2001-09-30', '2001-10-31', '2001-11-30', '2001-12-31', '2002-01-31', '2002-02-28', '2002-03-31', '2002-04-30', '2002-05-31', '2002-06-30', '2002-07-31', '2002-08-31', '2002-09-30', '2002-10-31', '2002-11-30', '2002-12-31', '2003-01-31', '2003-02-28', '2003-03-31', '2003-04-30', '2003-05-31', '2003-06-30', '2003-07-31', '2003-08-31', '2003-09-30', '2003-10-31', '2003-11-30', '2003-12-31', '2004-01-31', '2004-02-29', '2004-03-31', '2004-04-30', '2004-05-31', '2004-06-30', '2004-07-31', '2004-08-31', '2004-09-30', '2004-10-31', '2004-11-30', '2004-12-31', '2005-01-31', '2005-02-28', '2005-03-31', '2005-04-30', '2005-05-31', '2005-06-30', '2005-07-31', '2005-08-31', '2005-09-30', '2005-10-31', '2005-11-30', '2005-12-31', '2006-01-31', '2006-02-28', '2006-03-31', '2006-04-30', '2006-05-31', '2006-06-30', '2006-07-31', '2006-08-31', '2006-09-30', '2006-10-31', '2006-11-30', '2006-12-31', '2007-01-31', '2007-02-28', '2007-03-31', '2007-04-30', '2007-05-31', '2007-06-30', '2007-07-31', '2007-08-31', '2007-09-30', '2007-10-31', '2007-11-30', '2007-12-31', '2008-01-31', '2008-02-29', '2008-03-31', '2008-04-30', '2008-05-31', '2008-06-30', '2008-07-31', '2008-08-31', '2008-09-30', '2008-10-31', '2008-11-30', '2008-12-31', '2009-01-31', '2009-02-28', '2009-03-31', '2009-04-30', '2009-05-31', '2009-06-30', '2009-07-31', '2009-08-31', '2009-09-30', '2009-10-31', '2009-11-30', '2009-12-31', '2010-01-31', '2010-02-28', '2010-03-31', '2010-04-30', '2010-05-31', '2010-06-30', '2010-07-31', '2010-08-31', '2010-09-30', '2010-10-31', '2010-11-30', '2010-12-31', '2011-01-31', '2011-02-28', '2011-03-31', '2011-04-30', '2011-05-31', '2011-06-30', '2011-07-31', '2011-08-31', '2011-09-30', '2011-10-31', '2011-11-30', '2011-12-31', '2012-01-31', '2012-02-29', '2012-03-31', '2012-04-30', '2012-05-31', '2012-06-30', '2012-07-31', '2012-08-31', '2012-09-30', '2012-10-31', '2012-11-30', '2012-12-31', '2013-01-31', '2013-02-28', '2013-03-31', '2013-04-30', '2013-05-31', '2013-06-30', '2013-07-31', '2013-08-31', '2013-09-30', '2013-10-31', '2013-11-30', '2013-12-31', '2014-01-31', '2014-02-28', '2014-03-31', '2014-04-30', '2014-05-31', '2014-06-30', '2014-07-31', '2014-08-31', '2014-09-30', '2014-10-31', '2014-11-30', '2014-12-31', '2015-01-31', '2015-02-28', '2015-03-31', '2015-04-30', '2015-05-31', '2015-06-30', '2015-07-31', '2015-08-31', '2015-09-30', '2015-10-31', '2015-11-30', '2015-12-31', '2016-01-31', '2016-02-29', '2016-03-31', '2016-04-30', '2016-05-31', '2016-06-30', '2016-07-31', '2016-08-31', '2016-09-30', '2016-10-31', '2016-11-30', '2016-12-31', '2017-01-31', '2017-02-28', '2017-03-31', '2017-04-30', '2017-05-31', '2017-06-30', '2017-07-31', '2017-08-31', '2017-09-30', '2017-10-31', '2017-11-30', '2017-12-31', '2018-01-31', '2018-02-28', '2018-03-31', '2018-04-30', '2018-05-31', '2018-06-30', '2018-07-31', '2018-08-31', '2018-09-30', '2018-10-31', '2018-11-30', '2018-12-31', '2019-01-31', '2019-02-28', '2019-03-31', '2019-04-30', '2019-05-31', '2019-06-30', '2019-07-31', '2019-08-31', '2019-09-30', '2019-10-31', '2019-11-30', '2019-12-31', '2020-01-31', '2020-02-29', '2020-03-31', '2020-04-30', '2020-05-31', '2020-06-30', '2020-07-31', '2020-08-31', '2020-09-30', '2020-10-31', '2020-11-30', '2020-12-31', '2021-01-31', '2021-02-28', '2021-03-31', '2021-04-30', '2021-05-31', '2021-06-30', '2021-07-31', '2021-08-31', '2021-09-30', '2021-10-31', '2021-11-30', '2021-12-31', '2022-01-31', '2022-02-28', '2022-03-31', '2022-04-30', '2022-05-31', '2022-06-30', '2022-07-31', '2022-08-31', '2022-09-30', '2022-10-31', '2022-11-30', '2022-12-31'])\n",
    "\n",
    "df_value_city"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5df9a72c-0cd8-4d9d-aa22-4f1cc82acccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#takes zillow data and cleans it into just data by city 2023\n",
    "file_pathr = Path(\"Resources/City_zori_sm_month.csv\")\n",
    "df_rent_city = pd.read_csv(file_pathr)\n",
    "\n",
    "df_rent_city = df_rent_city.drop(columns=['2015-03-31', '2015-04-30', '2015-05-31', '2015-06-30', '2015-07-31', '2015-08-31', '2015-09-30', '2015-10-31', '2015-11-30', '2015-12-31', '2016-01-31', '2016-02-29', '2016-03-31', '2016-04-30', '2016-05-31', '2016-06-30', '2016-07-31', '2016-08-31', '2016-09-30', '2016-10-31', '2016-11-30', '2016-12-31', '2017-01-31', '2017-02-28', '2017-03-31', '2017-04-30', '2017-05-31', '2017-06-30', '2017-07-31', '2017-08-31', '2017-09-30', '2017-10-31', '2017-11-30', '2017-12-31', '2018-01-31', '2018-02-28', '2018-03-31', '2018-04-30', '2018-05-31', '2018-06-30', '2018-07-31', '2018-08-31', '2018-09-30', '2018-10-31', '2018-11-30', '2018-12-31', '2019-01-31', '2019-02-28', '2019-03-31', '2019-04-30', '2019-05-31', '2019-06-30', '2019-07-31', '2019-08-31', '2019-09-30', '2019-10-31', '2019-11-30', '2019-12-31', '2020-01-31', '2020-02-29', '2020-03-31', '2020-04-30', '2020-05-31', '2020-06-30', '2020-07-31', '2020-08-31', '2020-09-30', '2020-10-31', '2020-11-30', '2020-12-31', '2021-01-31', '2021-02-28', '2021-03-31', '2021-04-30', '2021-05-31', '2021-06-30', '2021-07-31', '2021-08-31', '2021-09-30', '2021-10-31', '2021-11-30', '2021-12-31', '2022-01-31', '2022-02-28', '2022-03-31', '2022-04-30', '2022-05-31', '2022-06-30', '2022-07-31', '2022-08-31', '2022-09-30', '2022-10-31', '2022-11-30', '2022-12-31'])\n",
    "\n",
    "#DOUBLE INDEX\n",
    "df_rent_city = df_rent_city.set_index(['RegionName','State'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1991935-4f9c-4417-9ea9-99742fd433fb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#creates data for price/ rent ratio\n",
    "df_pr = df_value_city.join(df_rent_city, rsuffix='_rent')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fcee07a-da06-4cf7-892e-7c498813ce7b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_pr.loc['Dallas','TX']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9858ce56-1ab2-4a3d-8c99-4238ceb05626",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "PR_Ratio = df_pr.loc[[('Dallas', 'TX'),('Austin', 'TX'),('San Antonio', 'TX'),('Houston', 'TX'),('Atlanta', 'GA'), ('Charlotte', 'NC'),('Jacksonville', 'FL'),('Tampa', 'FL'),('Orlando', 'FL'),('Miami', 'FL')], 'P/R Ratio']\n",
    "\n",
    "PR_Ratio = pd.DataFrame(PR_Ratio)\n",
    "PR_Ratio.plot.bar()\n",
    "\n",
    "# # top 10 cities\n",
    "# Dallas, TX\n",
    "# Austin, TX\n",
    "# San Antonio, TX\n",
    "# Houston, TX\n",
    "# Atlanta, GA\n",
    "# Charlotte, NC\n",
    "# Jacksonville, FL\n",
    "# Tampa, FL\n",
    "# Orlando, FL\n",
    "# Miami, FL\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "016a9244-d66e-4e55-8625-36720f13cd64",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
